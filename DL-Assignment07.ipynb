{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Transfer Learning\n",
    "\n",
    "\n",
    "The goal of this exercise is to learn how to use pre-trained networks in transfer learning tasks.\n",
    "We will make use of networks trained on ImageNet, and apply them to related problems, i.e., the classification of $10$ objects not contained in ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this exercise we use the  [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset that can be downloaded from the official website [here]({https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz}).\n",
    "The dataset contains $60000$ color images of pixels size $32\\times 32$ in $10$ classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck, with $6000$ images per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Transformation\n",
    "\n",
    "We need to instantiate a proper `torchvision.transform` instance to create the same input structure as used for training our network.\n",
    "We need to combine 4 transforms, which can be compiled from the PyTorch website: https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "1. We need to resize the image such that the shorter side has size 256.\n",
    "2. We need to take the center crop of size $224\\times224$ from the image.\n",
    "3. We need to convert the image into a tensor (including pixel values scaling)\n",
    "4. We need to normalize the pixel values with mean $(0.485, 0.456, 0.406)$ and standard deviation $(0.229, 0.224, 0.225)$.\n",
    "\n",
    "Since we will use networks pre-trained on ImageNet, we need to perform the exact same transform as used for ImageNet testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "\n",
    "#imagenet_transform = torchvision.transforms.Compose(\n",
    "#    [torchvision.transforms.Resize(256),\n",
    "#     torchvision.transforms.CenterCrop(224),\n",
    "#     torchvision.transforms.ToTensor,\n",
    "#     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Here I am working with the predefined transformation. The other one throws some errors in the assertion.\n",
    "imagenet_transform = ResNet50_Weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Dataset Loading\n",
    "\n",
    "We here use the [torchvision.datasets.CIFAR10](https://pytorch.org/vision/0.12/generated/torchvision.datasets.CIFAR10.html) dataset interface for processing images. \n",
    "You can use the `train` argument or flag to distinguish between training and test set.\n",
    "\n",
    "This task consists of two parts:\n",
    "\n",
    "1. Create two datasets, one for the training set, one for the test set. Use the transform defined above.\n",
    "2. Once the datasets are created, create two data loaders, one for training set, one for test set. Use a proper value of the batch-size $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data-cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 170498071/170498071 [00:16<00:00, 10518820.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data-cifar10/cifar-10-python.tar.gz to ./data-cifar10\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "  root = \"./data-cifar10\", # created a new folder ./data > ./data-cifar10\n",
    "  train=True, download=True,\n",
    "    transform=imagenet_transform\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "  root = \"./data-cifar10\", # created a new folder ./data > ./data-cifar10\n",
    "  train=False, download=True,\n",
    "    transform=imagenet_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 64\n",
    "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=B)\n",
    "testloader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Data Size and Types\n",
    "\n",
    "We check that all input images are `torch.tensors` of size $3\\times224\\times224$ and of type `torch.float` and that all labels are of type `int`.\n",
    "\n",
    "Note: the sanity check is only performed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, t in testset:\n",
    "  assert isinstance(x, torch.Tensor)\n",
    "  assert isinstance(t, int)\n",
    "  assert x.shape==(3,224,224)\n",
    "  assert x.dtype==torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feature Extraction\n",
    "\n",
    "We will use a pre-trained network available in `PyTorch`. \n",
    "Particularly, we will use a ResNet-50 architecture, but other architectures can also be tested. \n",
    "Fortunately, PyTorch provides simple interfaces to obtain pre-trained models, e.g., using the `torchvision.models.resnet50` interface function.\n",
    "\n",
    "In order to use the networks in a different dataset, we need to change their outputs. \n",
    "There are several possibilities on how to achieve that, and you have the freedom to choose. \n",
    "\n",
    "For your reference, the implementation of the `forward` function of ResNet networks (including ResNet-50) can be found here: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L266\n",
    "\n",
    "You can also check if other networks perform better, for example, deeper ResNet topologies.\n",
    "Be aware that the strategy to replace the last fully-connected layer might not work in other network topologies, only in residual networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Pre-trained Network Instantiation\n",
    "\n",
    "Instantiate two pre-trained networks of type ResNet-50.\n",
    "\n",
    "1. Freeze the feature layers of the first network.\n",
    "\n",
    "Note: Make use the `old TorchVision Interface` to load your pre-trained network. Here is the link: https://pytorch.org/vision/0.12/models.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sascha/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sascha/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# instantiate the first pre-trained resnet 50 network\n",
    "\n",
    "network_1 = torchvision.models.resnet50(pretrained=True)\n",
    "# Make sure to freeze all the layers of the network.\n",
    "for param in network_1.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "# instantiate the second pre-trained resnet 50 network (optinally)\n",
    "network_2 = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Network Implementation\n",
    "\n",
    "We want to modify the network such that we extract the logits for the 10 classes from CIFAR-10 from the last fully-connected layer of the network.\n",
    "\n",
    "Implement a function that:\n",
    "1. Replaces the current last linear layer of the pre-trained network with a new linear layer that has $O$ units ($O$ represents the number of classes in our dataset).\n",
    "2. Initialize the weights of the new linear layer using Xavier's method **(Optional)**.\n",
    "\n",
    "Note: Use `torch.nn.init.xavier_uniform_` function to initialize the weights of the new linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc Linear(in_features=2048, out_features=1000, bias=True)\n",
      "fc Linear(in_features=2048, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name, layer in network_1.named_modules():\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "        print(name, layer)\n",
    "        layer = torch.nn.Linear(2048, 10)\n",
    "        print(name, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_last_layer(network, O=10):\n",
    "  # replace the last linear layer with the new layer\n",
    "  for name, layer in network_1.named_modules():\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "        network._modules[name] = torch.nn.Linear(2048, O)\n",
    "\n",
    "  return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Last layer dimensions\n",
    "\n",
    "This test ensures that the function return a network having the correct number of input and output units in the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = 10\n",
    "for network in (network_1, network_2):\n",
    "    new_model = replace_last_layer(network, O=O)\n",
    "    assert new_model.fc.out_features == O\n",
    "    assert new_model.fc.in_features == 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Training\n",
    "Implement a function that takes all necessary parameters to run a training on a given dataset. \n",
    "Select the optimizer to be `torch.optim.SGD` and `torch.nn.CrossEntropyLoss` as the loss function. \n",
    "The test set will be used as the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Training and Evaluation Loop\n",
    "\n",
    "Implement a training loop over a specific number of epochs (10) with a learning rate of $\\eta=0.001$ and momentum of $\\mu = 0.9$. \n",
    "Make sure that you train on the training data only, and `not` on the validation data.\n",
    "In each loop, compute and print the training loss, training accuracy, validation loss and validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(...):\n",
    "    optimizer = torch.optim.SGD(...)\n",
    "\n",
    "    train_loss, train_acc = [], []\n",
    "    test_loss, test_acc = [], []\n",
    "\n",
    "    for epoch in range(...):\n",
    "        \n",
    "        # training process\n",
    "        ...\n",
    "\n",
    "        # testing process\n",
    "        ...\n",
    "\n",
    "        # print accuracies and losses for current epoch\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Network Fine-Tuning with Frozen Layers\n",
    "\n",
    "Create a network that has feature layers frozen with $10$ output units. \n",
    "Fine-tune the created network on our CIFAR-10 data using the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_with_frozen_layers = ...\n",
    "train_eval(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (Optional): Network Fine-Tuning without Frozen Layers \n",
    "\n",
    "Create a network from the second pre-trained network with $10$ output units. \n",
    "Fine-tune the created network on our CIFAR-10.\n",
    "\n",
    "Note:\n",
    "\n",
    "  * The fine-tuning of the network can take a long time when the layers are not frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_normal = ...\n",
    "train_eval(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Finally, we want to plot the confusion matrix of the test set.\n",
    "For this, we need to compute the predictions for all of our test samples, and the list of target values.\n",
    "Finally, we can make use of the `sklearn.metrics.confusion_matrix` to compute the confusion matrix.\n",
    "You can utilize `sklearn.metrics.ConfusionMatrixDisplay` for displaying the confusion matrix, or `pyplot.imshow` and adding the according labels.\n",
    "\n",
    "Note:\n",
    "\n",
    "  * The documentation for the confusion matrix can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "  * The interface and an example for the `ConfusionMatrixDisplay` can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Confusion Matrix Plotting\n",
    "\n",
    "Plot the confusion matrix for the fine-tuned network with frozen layers.\n",
    "Optionally, also plot the confusion matrix for the second fine-tuned network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# compute predictions and collect targets\n",
    "predictions = ...\n",
    "targets = ...\n",
    "\n",
    "# compute confusion matrix\n",
    "matrix = confusion_matrix(...)\n",
    "\n",
    "# plot confusion matrix\n",
    "...\n",
    "\n",
    "# add axis labels if required\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
